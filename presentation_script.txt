CI-LLM: WEAVING A "CROWD WITHIN" A SINGLE AI
5-Minute Final Project Presentation Script
Avi Oberoi - MACS 30123: Large-Scale Computing for the Social Sciences

===============================================================================
INTRODUCTION & SOCIAL SCIENCE PROBLEM (90 seconds)
===============================================================================

[SLIDE 1: Title]
Hello, I'm Avi Oberoi, and today I'll present CI-LLM - Collective Intelligence-informed Large Language Models, a project that tackles a fundamental limitation in artificial intelligence through large-scale computing.

[SLIDE 2: The Problem]
Current large language models like Gemma operate as single, powerful "minds." While impressive, this creates critical limitations when we need true multi-perspective understanding:

First, BRITTLENESS - single models have specific failure modes and blind spots. 
Second, BIAS ENTRENCHMENT - they reflect dominant narratives without surfacing alternative viewpoints.
Third, DIFFICULTY REPRESENTING NUANCE - while models can be prompted for different personas, their core reasoning pathways often converge.

[SLIDE 3: Research Question]
This leads to our core social science question: Can we create an AI that doesn't just mimic different perspectives when prompted, but actually fosters internal collective intelligence? Can we build AI that benefits from the "wisdom of crowds" by having multiple, independent, diverse reasoning pathways within its own structure?

This question is crucial for understanding how artificial systems can better model the complex, multi-faceted nature of human discourse and decision-making that characterizes real-world social phenomena.

===============================================================================
WHY LARGE-SCALE COMPUTING IS ESSENTIAL (75 seconds)
===============================================================================

[SLIDE 4: Computational Challenges]
Solving this problem requires large-scale computing across multiple dimensions:

MODEL COMPLEXITY: Our implementation uses Gemma-2-2B with K=4 independent agents, each requiring separate LoRA adapters. This creates 2 billion base parameters plus adapter weights.

TRAINING COMPLEXITY: We implement diversity regularization using Sliced Wasserstein Distance to force agents to learn different reasoning patterns, while simultaneously optimizing for task performance. This dual-objective creates conflicting gradients requiring sophisticated optimization.

DATA PROCESSING SCALE: GSM8K dataset requires distributed tokenization and format conversion. Standard approaches can't handle the memory requirements for multi-agent training data preparation.

[SLIDE 5: Scalability Requirements]
Why standard computing fails:
- Memory constraints: Standard GPUs cannot accommodate multi-agent training
- Processing bottlenecks: Sequential data preprocessing becomes a training bottleneck
- Training time: Without parallelization, training would take weeks instead of days
- Research scalability: Experimenting with larger models and more agents requires cluster resources

Large-scale computing isn't just helpful - it's fundamental to making collective intelligence research feasible.

===============================================================================
LARGE-SCALE COMPUTING STRATEGIES (120 seconds)
===============================================================================

[SLIDE 6: Strategy Overview]
We implemented four integrated large-scale computing strategies:

STRATEGY 1: APACHE SPARK DISTRIBUTED PREPROCESSING
We developed a custom Spark implementation for distributed data processing. Using PySpark User-Defined Functions, we parallelize tokenization across cluster nodes. This converts Hugging Face datasets to optimized Parquet format with automatic schema enforcement. Spark's lazy evaluation prevents memory overflow, while RDD lineage provides fault tolerance.

STRATEGY 2: DEEPSPEED ZERO-2 INTEGRATION  
For memory optimization during training, we use DeepSpeed ZeRO-2 to shard optimizer states and gradients across GPUs. This dramatically reduces VRAM per GPU, enabling larger models. We integrated this with custom multi-adapter checkpointing for our K=4 agent architecture.

STRATEGY 3: HUGGING FACE ACCELERATE
Accelerate provides seamless distributed training abstraction with automatic device placement and mixed precision training using bfloat16. This handles the complexity of multi-GPU coordination while maintaining compatibility with our custom model architecture.

STRATEGY 4: PARALLEL AGENT ARCHITECTURE
We implemented two execution modes: sequential and parallel. In parallel mode, we create K separate PeftModel instances sharing frozen base model weights through PyTorch tensor storage. This enables true parallel agent execution and reduces adapter switching overhead.

[SLIDE 7: Integration]
These strategies work together: Spark preprocessing feeds optimized data to Accelerate-coordinated training, while DeepSpeed handles memory constraints, and our parallel architecture maximizes computational efficiency.

===============================================================================
RESULTS AND IMPACT (45 seconds)
===============================================================================

[SLIDE 8: Results]
Our evaluation revealed 0% accuracy on GSM8K, but this failure taught us critical lessons about multi-objective optimization in AI systems.

We identified that the conflicting objectives between cross-entropy loss and diversity regularization prevented convergence. The Sliced Wasserstein term actively penalized agent agreement, creating gradient interference that prevented coherent mathematical reasoning.

[SLIDE 9: Contributions]
This project demonstrates three key contributions:

First, we proved that complex collective intelligence architectures require sophisticated large-scale computing strategies - our Spark preprocessing handles dataset scalability, while DeepSpeed and Accelerate make multi-agent training feasible.

Second, we identified fundamental optimization challenges in multi-objective AI training that future research must address.

Third, we created a scalable infrastructure that can support larger models and more agents for continued collective intelligence research.

===============================================================================
CONCLUSION (30 seconds)
===============================================================================

[SLIDE 10: Future Work]
CI-LLM demonstrates that modeling collective intelligence in AI requires large-scale computing not just for scale, but for fundamental feasibility. Our infrastructure supports future work on loss function rebalancing, larger agent configurations, and streaming data processing.

The "wisdom of crowds" in AI remains an open challenge, but our large-scale computing foundation provides the tools to tackle it.

Thank you for your attention.

===============================================================================
TIMING GUIDE:
- Introduction & Problem: 90 seconds (0:00-1:30)
- Computing Justification: 75 seconds (1:30-2:45)
- Computing Strategies: 120 seconds (2:45-4:45)
- Results & Conclusion: 75 seconds (4:45-6:00)
- Buffer for questions: 60 seconds

PRESENTATION TIPS:
- Speak at ~150 words per minute
- Use visual aids for architecture diagrams
- Practice transitions between sections
- Have backup slides for technical details
- End with clear takeaways about large-scale computing necessity
=============================================================================== 